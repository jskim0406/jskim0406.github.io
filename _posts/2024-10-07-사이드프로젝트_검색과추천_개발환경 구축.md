---
layout: post
title: 검색과 추천 - (사이드 플젝) 개발환경 구축(elasticsearch, kibana, spark, kafka, jupyter notebook)
author: jskim
featuredImage: null
img: null
tags: Elasticsearch, Retrieval, Kibana, Spark, Kafka, Microservice, Docker, Recommendation system, Search Engine, Side project, VectorDB
categories: Retrieval
date: '2024-10-07 01:25:00 +0900'
---


# Ubuntu에서 마이크로서비스 개발 환경 구축 가이드

이 가이드는 Docker가 설치된 Ubuntu 환경에서 Java, Elasticsearch, Spark, Kafka, Jupyter Notebook 등을 포함하는 마이크로서비스 개발 환경을 구축하는 방법을 단계별로 설명합니다.

<div style="background-color: #333840; border-left: 6px solid #4A90E2; padding: 10px; color: #e0e0e0;">
  <strong>Info</strong>: 본 사이드 프로젝트는 Google Cloud Platform(GCP)의 Ubuntu OS의 VM에서 진행했습니다. 아래 개발환경 또한 해당 VM에 구축했습니다.
</div>


<div style="background-color: #333840; border-left: 6px solid #4A90E2; padding: 10px; color: #e0e0e0;">
  <strong>Info</strong>: 본 가이드는 사이드 프로젝트를 진행하는 과정에서 필요한 개발환경을 구축하는 과정을 담고 있습니다. 30분여 정도 `ChatGPT`, `Claude`와 문답을 주고 받으며 작성한 가이드 문서입니다.
</div>

---

## 목차

1. [환경 준비](#1-환경-준비)
2. [Elasticsearch 및 Kibana 설정](#2-elasticsearch-및-kibana-설정)
3. [Java 설치 및 환경 변수 설정](#3-java-설치-및-환경-변수-설정)
4. [Spark 설치 및 설정](#4-spark-설치-및-설정)
5. [Spark와 Elasticsearch 연동](#5-spark와-elasticsearch-연동)
6. [Kafka 설정](#6-kafka-설정)
7. [Jupyter Notebook 설치 및 설정 (선택 사항)](#7-jupyter-notebook-설치-및-설정-선택-사항)
8. [마이크로서비스 개발 환경 구축 완료](#8-마이크로서비스-개발-환경-구축-완료)

---

## 1. 환경 준비

### 1.1 Docker 설치 확인

Ubuntu에 Docker가 이미 설치되어 있는지 확인합니다.

```bash
docker --version
```
Docker가 설치되어 있지 않다면, [Docker 공식 문서](https://docs.docker.com/engine/install/ubuntu/)를 참고하여 설치하세요.

---

## 2. Elasticsearch 및 Kibana 설정

### 2.1 Elasticsearch 및 Kibana 이미지 다운로드

```bash
sudo docker pull docker.elastic.co/elasticsearch/elasticsearch:8.15.0
sudo docker pull docker.elastic.co/kibana/kibana:8.15.0
```

### 2.2 Docker 네트워크 생성

Elasticsearch와 Kibana가 통신할 수 있도록 Docker 네트워크를 생성합니다.

```bash
sudo docker network create elastic
```

### 2.3 Elasticsearch 컨테이너 실행

```bash
sudo docker run -d \
  --name elasticsearch \
  --net elastic \
  -p 9200:9200 \
  -p 9300:9300 \
  -e "discovery.type=single-node" \
  -e "ELASTIC_PASSWORD=password" \
  -e "xpack.security.enabled=false" \
  -e "xpack.security.enrollment.enabled=false" \
  docker.elastic.co/elasticsearch/elasticsearch:8.15.0
```

### 2.4 Kibana 컨테이너 실행

```bash
sudo docker run -d \
  --name kibana \
  --net elastic \
  -p 5601:5601 \
  docker.elastic.co/kibana/kibana:8.15.0
```

### 2.5 Kibana 접속 확인

웹 브라우저에서 [http://localhost:5601](http://localhost:5601)에 접속하여 Kibana가 정상적으로 실행되는지 확인합니다.

- **로그인 정보**:
  - 아이디: `elastic`
  - 비밀번호: `password`

---

## 3. Java 설치 및 환경 변수 설정

### 3.1 OpenJDK 17 설치

```bash
sudo apt update
sudo apt install -y openjdk-17-jdk
```

### 3.2 JAVA_HOME 환경 변수 설정

`~/.bashrc` 파일을 편집하여 환경 변수를 설정합니다.

```bash
echo 'export JAVA_HOME=$(dirname $(dirname $(readlink -f $(which javac))))' >> ~/.bashrc
echo 'export PATH=$JAVA_HOME/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

### 3.3 Java 설치 확인

```bash
java -version
echo $JAVA_HOME
```

---

## 4. Spark 설치 및 설정

### 4.1 Spark 다운로드

```bash
curl -O https://dlcdn.apache.org/spark/spark-3.4.3/spark-3.4.3-bin-hadoop3.tgz
```

### 4.2 Spark 압축 해제 및 이동

```bash
tar -xzf spark-3.4.3-bin-hadoop3.tgz
sudo mv spark-3.4.3-bin-hadoop3 /opt/spark-3.4.3
```

### 4.3 Spark 설정 파일 복사 및 수정

```bash
sudo cp /opt/spark-3.4.3/conf/spark-defaults.conf.template /opt/spark-3.4.3/conf/spark-defaults.conf
echo 'spark.driver.extraJavaOptions   -Djava.security.manager=allow' | sudo tee -a /opt/spark-3.4.3/conf/spark-defaults.conf
echo 'spark.executor.extraJavaOptions   -Djava.security.manager=allow' | sudo tee -a /opt/spark-3.4.3/conf/spark-defaults.conf
```

### 4.4 심볼릭 링크 생성

```bash
sudo ln -s /opt/spark-3.4.3 /opt/spark
```

### 4.5 SPARK_HOME 환경 변수 설정

`~/.bashrc` 파일에 다음을 추가합니다.

```bash
echo 'export SPARK_HOME=/opt/spark' >> ~/.bashrc
echo 'export PATH=$SPARK_HOME/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

### 4.6 Spark 설치 확인

```bash
spark-shell --version
```

---

## 5. Spark와 Elasticsearch 연동

### 5.1 Elasticsearch Spark 커넥터 JAR 파일 다운로드

```bash
curl -L -o elasticsearch-spark-30_2.12-8.15.0.jar \
"https://repo1.maven.org/maven2/org/elasticsearch/elasticsearch-spark-30_2.12/8.15.0/elasticsearch-spark-30_2.12-8.15.0.jar"
```

### 5.2 JAR 파일을 Spark의 JAR 디렉토리로 이동

```bash
sudo mv elasticsearch-spark-30_2.12-8.15.0.jar /opt/spark-3.4.3/jars/
```

---

## 6. Kafka 설정

### 6.1 Docker Compose 파일 작성

프로젝트 디렉토리에 `docker-compose.yml` 파일을 생성하고 다음 내용을 추가합니다.

```yaml
version: '3.8'

services:
  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
    networks:
      - kafka-net

  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_LISTENERS=PLAINTEXT://:9092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
      - ALLOW_PLAINTEXT_LISTENER=yes
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    networks:
      - kafka-net

networks:
  kafka-net:
    driver: bridge
```

### 6.2 Kafka 및 Zookeeper 실행

```bash
docker-compose up -d
```

### 6.3 Kafka 동작 확인

Kafka CLI 도구를 사용하여 토픽을 생성하고 메시지를 주고받을 수 있습니다.

---

## 7. Jupyter Notebook 설치 및 설정 (선택 사항)

### 7.1 Python 3.9 설치

```bash
sudo apt update
sudo apt install -y python3.9 python3.9-venv python3.9-dev
```

### 7.2 pip 및 Jupyter Notebook 설치

```bash
curl -sS https://bootstrap.pypa.io/get-pip.py | sudo python3.9
sudo python3.9 -m pip install jupyter ipykernel
```

### 7.3 Python 3.9 커널 추가

```bash
python3.9 -m ipykernel install --user --name="Python-3.9"
```

### 7.4 Jupyter Notebook에서 Spark 연동 환경 변수 설정

`~/.bashrc` 파일에 다음을 추가합니다.

```bash
echo 'export PYSPARK_PYTHON=python3.9' >> ~/.bashrc
echo 'export PYSPARK_DRIVER_PYTHON=jupyter' >> ~/.bashrc
echo 'export PYSPARK_DRIVER_PYTHON_OPTS="notebook --no-browser --port=8889"' >> ~/.bashrc
source ~/.bashrc
```

### 7.5 Jupyter Notebook 실행

```bash
pyspark
```

- 터미널에 표시되는 URL을 복사하여 웹 브라우저에서 Jupyter Notebook에 접속합니다.
- Spark 세션이 자동으로 생성되며, Spark와의 연동이 가능합니다.

---

## 8. 마이크로서비스 개발 환경 구축 완료

이제 Ubuntu 환경에서 Docker를 활용하여 Java, Elasticsearch, Spark, Kafka, Jupyter Notebook 등을 포함하는 마이크로서비스 개발 환경을 성공적으로 구축하였습니다.

---

## 요약

이 가이드는 Ubuntu에서 마이크로서비스 개발 환경을 구축하기 위한 단계별 지침을 제공합니다. Docker를 활용하여 주요 애플리케이션들을 컨테이너화하고, 필요한 설정을 통해 서비스 간 연동을 구현하였습니다. 이 환경에서 마이크로서비스를 개발하고 배포할 수 있으며, 추가적인 요구 사항에 따라 확장 및 최적화가 가능합니다.
